---
# ============================================================================
# SPEC METADATA - Task specification
# ============================================================================

# === IDENTIFICATION ===
id: '1023'
title: 'Docker and Database Services Setup'
type: 'task'

# === HIERARCHY ===
parent: '1002'
children: []
epic: '1000'
domain: 'infrastructure'

# === WORKFLOW ===
status: 'draft'
priority: 'high'

# === TRACKING ===
created: '2025-08-27'
updated: '2025-08-27'
due_date: ''
estimated_hours: 3
actual_hours: 0

# === DEPENDENCIES ===
dependencies: ['1021'] # Requires Node.js for some scripts
blocks: ['1024', '1025', '1026']
related: []

# === IMPLEMENTATION ===
pull_requests: []
commits: []
context_file: "1023.context.md"
files: ['docker-compose.dev.yml', 'scripts/docker-setup.sh', 'configs/redis.conf', 'configs/postgres-init.sql']

# === METADATA ===
tags: ['docker', 'database', 'postgres', 'mongodb', 'redis', 'clickhouse', 'kafka']
effort: 'medium'
risk: 'medium'

# ============================================================================
---

# Docker and Database Services Setup

## Overview

Set up Docker environment with all required database and messaging services for local development, including PostgreSQL, ClickHouse, MongoDB, Redis, Kafka, and monitoring tools. Configure multi-account support infrastructure.

## Acceptance Criteria

- [ ] Docker and Docker Compose installed on Linux and Windows
- [ ] PostgreSQL configured with development database
- [ ] ClickHouse set up for time-series data
- [ ] MongoDB configured for configuration storage
- [ ] Redis configured with database allocation for multi-accounts
- [ ] Kafka and Zookeeper operational
- [ ] Grafana monitoring dashboard (optional)
- [ ] All services accessible and healthy
- [ ] Initialization scripts for databases
- [ ] Volume persistence configured

## Technical Approach

### Docker Compose Configuration (`docker-compose.dev.yml`)

```yaml
version: '3.8'

services:
  # PostgreSQL - Core business data
  postgres:
    image: postgres:15-alpine
    container_name: jts-postgres-dev
    restart: unless-stopped
    ports:
      - "5432:5432"
    environment:
      POSTGRES_DB: jts_trading_dev
      POSTGRES_USER: jts_admin
      POSTGRES_PASSWORD: dev_password
    volumes:
      - postgres_dev_data:/var/lib/postgresql/data
      - ./scripts/init-postgres.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U jts_admin -d jts_trading_dev"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ClickHouse - Time-series market data
  clickhouse:
    image: clickhouse/clickhouse-server:23.8
    container_name: jts-clickhouse-dev
    restart: unless-stopped
    ports:
      - "8123:8123"
      - "9000:9000"
    environment:
      CLICKHOUSE_DB: jts_market_data_dev
      CLICKHOUSE_USER: jts_ch
      CLICKHOUSE_PASSWORD: dev_password
    volumes:
      - clickhouse_dev_data:/var/lib/clickhouse
      - ./configs/clickhouse-config.xml:/etc/clickhouse-server/config.xml
    ulimits:
      nofile:
        soft: 262144
        hard: 262144

  # MongoDB - Configuration storage
  mongodb:
    image: mongo:7
    container_name: jts-mongodb-dev
    restart: unless-stopped
    ports:
      - "27017:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: jts_mongo
      MONGO_INITDB_ROOT_PASSWORD: dev_password
      MONGO_INITDB_DATABASE: jts_config_dev
    volumes:
      - mongodb_dev_data:/data/db
      - ./scripts/init-mongo.js:/docker-entrypoint-initdb.d/init.js

  # Redis - Caching and rate limiting
  redis:
    image: redis:7-alpine
    container_name: jts-redis-dev
    restart: unless-stopped
    ports:
      - "6379:6379"
    command: redis-server /usr/local/etc/redis/redis.conf
    volumes:
      - redis_dev_data:/data
      - ./configs/redis.conf:/usr/local/etc/redis/redis.conf

  # Kafka & Zookeeper
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: jts-zookeeper-dev
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: jts-kafka-dev
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  # Monitoring (Optional)
  grafana:
    image: grafana/grafana:latest
    container_name: jts-grafana-dev
    ports:
      - "3100:3000"
    environment:
      GF_SECURITY_ADMIN_PASSWORD: dev_password
    volumes:
      - grafana_dev_data:/var/lib/grafana

volumes:
  postgres_dev_data:
  clickhouse_dev_data:
  mongodb_dev_data:
  redis_dev_data:
  grafana_dev_data:

networks:
  default:
    name: jts-dev-network
```

### Redis Configuration for Multi-Account (`configs/redis.conf`)

```conf
# Redis configuration for multi-account support
databases 16

# Database allocation:
# 0: Session cache
# 1: KIS account 1 rate limits
# 2: KIS account 2 rate limits
# 3: Surge detection cache
# 4: Order queue
# 5: Account metrics
# 6-15: Reserved for future use

save 900 1
save 300 10
save 60 10000

appendonly yes
appendfsync everysec
```

### Database Initialization Scripts

**PostgreSQL** (`scripts/init-postgres.sql`):
```sql
-- Create schemas
CREATE SCHEMA IF NOT EXISTS trading;
CREATE SCHEMA IF NOT EXISTS analytics;

-- Create tables
CREATE TABLE IF NOT EXISTS trading.orders (
    id UUID PRIMARY KEY,
    symbol VARCHAR(20) NOT NULL,
    account_id VARCHAR(50) NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Create indexes
CREATE INDEX idx_orders_account ON trading.orders(account_id);
CREATE INDEX idx_orders_created ON trading.orders(created_at);
```

## Implementation Steps

1. **Install Docker** (30 min)
   - Linux: Docker Engine installation
   - Windows: Docker Desktop setup
   - Verify installation

2. **Create Docker Compose File** (45 min)
   - Define all services
   - Configure networking
   - Set up volumes

3. **Configure Databases** (45 min)
   - Create initialization scripts
   - Set up Redis for multi-account
   - Configure database schemas

4. **Test Services** (45 min)
   - Start all containers
   - Verify connectivity
   - Test health checks

5. **Create Helper Scripts** (15 min)
   - Start/stop scripts
   - Health check script
   - Data reset script

## Deliverables

- `docker-compose.dev.yml` - Complete Docker configuration
- `configs/redis.conf` - Redis configuration for multi-account
- `scripts/init-postgres.sql` - PostgreSQL initialization
- `scripts/init-mongo.js` - MongoDB initialization
- `scripts/docker-setup.sh` - Docker installation script
- `scripts/dev-services.sh` - Service management script

## Testing Plan

- Verify all containers start successfully
- Test database connections
- Validate Redis database allocation
- Check Kafka message publishing
- Test data persistence across restarts
- Verify health checks work

## Notes

- Redis databases are pre-allocated for multi-account rate limiting
- Grafana is optional but recommended for monitoring
- All services use dev_password for local development only