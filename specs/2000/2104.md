---
# ============================================================================
# SPEC METADATA - This entire frontmatter section contains the spec metadata
# ============================================================================

# === IDENTIFICATION ===
id: '2104' # Numeric ID for stable reference
title: 'Redis-based Distributed Rate Limiting System'
type: 'feature' # prd | epic | feature | task | subtask | bug | spike

# === HIERARCHY ===
parent: '2000' # Parent spec ID (broker integration epic)
children: [] # Child spec IDs (if any)
epic: '2000' # Root epic ID for this work
domain: 'infrastructure-rate-limiting' # Business domain

# === WORKFLOW ===
status: 'draft' # draft | reviewing | approved | in-progress | testing | done
priority: 'high' # high | medium | low

# === TRACKING ===
created: '2025-08-25' # YYYY-MM-DD
updated: '2025-08-25' # YYYY-MM-DD
due_date: '' # YYYY-MM-DD (optional)
estimated_hours: 30 # Time estimate in hours
actual_hours: 0 # Time spent so far

# === DEPENDENCIES ===
dependencies: ['1000'] # Must be done before this (foundation - Redis)
blocks: ['2105', '2106'] # Blocks account management and routing
related: ['2101', '2102', '2103'] # Related to all broker integrations

# === IMPLEMENTATION ===
branch: '' # Git branch name
files: ['libs/shared/services/rate-limiter.service.ts', 'libs/shared/redis/', 'apps/brokers/common/rate-limiting/'] # Key files to modify

# === METADATA ===
tags: ['rate-limiting', 'redis', 'distributed', 'performance', 'compliance'] # Searchable tags
effort: 'medium' # small | medium | large | epic
risk: 'medium' # low | medium | high (critical for API compliance)

# ============================================================================
---

# Redis-based Distributed Rate Limiting System

## Overview

Implement a comprehensive distributed rate limiting system using Redis to prevent API violations across all broker services with intelligent request queuing and prioritization. This feature ensures compliance with strict broker API limits (KIS: 20/sec, 1000/min; Creon: 15/60sec) while maximizing throughput through request batching, priority queuing, and cross-account coordination.

## Acceptance Criteria

- [ ] Redis-based distributed rate limiter implemented
- [ ] Sliding window algorithm with sub-second precision
- [ ] Priority queue system for critical operations
- [ ] Support for multiple rate limit windows (per-second, per-minute, per-hour)
- [ ] Exponential backoff on rate limit violations
- [ ] Request batching optimization for efficiency
- [ ] Cross-account request coordination
- [ ] Rate limit monitoring and alerting
- [ ] Configurable rate limits per broker
- [ ] Emergency override capability
- [ ] Predictive throttling to prevent violations
- [ ] 80% safety buffer enforcement
- [ ] Real-time utilization dashboards
- [ ] <1ms Redis operation latency

## Technical Approach

### Rate Limiting Architecture

Build a distributed rate limiting system using Redis as the central coordination point, implementing sliding window counters with atomic operations to ensure accurate rate tracking across multiple service instances.

### Key Components

1. **Rate Limiter Core**
   - Sliding window counter implementation
   - Atomic Redis operations (INCR, EXPIRE)
   - Multi-window tracking (second, minute, hour)
   - Token bucket algorithm option
   - Leaky bucket algorithm option

2. **Priority Queue System**
   - Four priority levels: Critical, High, Normal, Low
   - Request queuing with TTL
   - Fair scheduling algorithm
   - Starvation prevention
   - Queue overflow handling

3. **Request Batching**
   - Intelligent request aggregation
   - Batch window configuration
   - API-specific batching rules
   - Response disaggregation
   - Error handling per item

4. **Broker Configuration**
   - Per-broker rate limit settings
   - Dynamic configuration updates
   - Multi-account limit aggregation
   - Environment-specific limits
   - Safety buffer configuration

5. **Monitoring & Alerting**
   - Real-time utilization tracking
   - Violation detection and logging
   - Predictive limit approaching alerts
   - Historical usage analytics
   - Dashboard visualizations

### Implementation Steps

1. **Setup Redis Infrastructure**
   - Configure Redis cluster for HA
   - Implement connection pooling
   - Setup Redis Sentinel
   - Configure persistence
   - Add monitoring

2. **Implement Core Algorithm**
   - Sliding window counter logic
   - Redis Lua scripts for atomicity
   - Window bucket management
   - Expiration handling
   - Counter accuracy validation

3. **Build Priority Queue**
   - Queue data structure in Redis
   - Priority-based sorting
   - Request metadata storage
   - TTL management
   - Dequeue algorithms

4. **Create Batching System**
   - Batch accumulator service
   - Timer-based flush
   - Size-based flush
   - API compatibility checks
   - Response routing

5. **Add Broker Adapters**
   - KIS rate limit adapter
   - Creon rate limit adapter
   - Binance/Upbit adapters
   - Configuration loaders
   - Limit validators

6. **Implement Monitoring**
   - Metrics collection service
   - Grafana dashboards
   - Alert rule configuration
   - Usage reports
   - Compliance tracking

## Rate Limit Specifications

### Broker Limits
```typescript
KIS: {
  perSecond: 20,
  perMinute: 1000,
  perHour: 50000,
  safetyBuffer: 0.8  // Use 80% of limits
}

Creon: {
  per60Seconds: 15,
  safetyBuffer: 0.8  // Use 12 requests
}

Binance: {
  weight: 1200,      // Per minute weight
  orders: 100,       // Per 10 seconds
  perDay: 200000     // Daily limit
}
```

### Priority Levels
```typescript
enum Priority {
  CRITICAL = 0,  // Order cancellations, risk management
  HIGH = 1,      // Order placement, modifications
  NORMAL = 2,    // Balance queries, position checks
  LOW = 3        // Historical data, analytics
}
```

### Redis Data Structures
```
rate_limit:{broker}:{account}:{window} - Counter
queue:{broker}:{priority} - Sorted set for queue
batch:{broker}:{batch_id} - Hash for batch data
config:{broker} - Hash for configuration
```

## Performance Requirements

### Latency Targets
- Rate check operation: <1ms
- Queue enqueue: <2ms
- Queue dequeue: <2ms
- Batch processing: <10ms
- Configuration update: <5ms

### Throughput
- 10,000+ rate checks per second
- 1,000+ queue operations per second
- Horizontal scaling support
- Zero downtime updates

### Reliability
- 99.99% availability
- No data loss on Redis failure
- Automatic failover
- Graceful degradation

## Trading-Specific Requirements

### Critical Operation Handling
- Emergency order cancellations bypass queue
- Risk management operations get priority
- Market close operations prioritized
- Stop-loss orders never delayed

### Cross-Account Coordination
- Aggregate limits across accounts
- Fair distribution algorithm
- Account priority settings
- Symbol-based allocation

### Compliance Features
- Audit trail of all rate limit decisions
- Violation reporting
- Regulatory compliance logs
- Rate limit usage reports

## Dependencies

- **1000**: Foundation Infrastructure - Requires Redis setup
- All broker features (2101, 2102, 2103) integrate with this

## Testing Plan

- Unit tests for rate limiting algorithms
- Integration tests with Redis cluster
- Load testing at maximum throughput
- Failover scenario testing
- Priority queue fairness tests
- Batching efficiency tests
- Multi-account coordination tests
- Memory leak detection
- Performance benchmarks
- Compliance verification

## Claude Code Instructions

```
When implementing this feature:
1. Use Redis Lua scripts for atomic operations
2. Implement sliding window with millisecond precision
3. Use Redis sorted sets for priority queues
4. Create NestJS service with dependency injection
5. Use Bull queue for background processing if needed
6. Implement circuit breaker for Redis failures
7. Add comprehensive logging with request IDs
8. Use Redis pipelining for batch operations
9. Implement exponential backoff: 100ms, 200ms, 400ms, 800ms
10. Create health check endpoints
11. Use Redis Streams for event logging
12. Implement rate limit headers in responses
13. Add Prometheus metrics for monitoring
14. Test with Redis failure scenarios
15. Ensure idempotent operations
```

## Monitoring & Observability

### Metrics to Track
- Current utilization per broker/window
- Queue depth per priority
- Request latency percentiles
- Violation count and patterns
- Batch efficiency ratios
- Redis operation latency

### Dashboards
- Real-time rate limit utilization
- Queue status visualization
- Historical usage patterns
- Violation heat maps
- Performance metrics

### Alerts
- Approaching rate limit (>70%)
- Rate limit violation
- Queue overflow
- Redis connection issues
- Abnormal usage patterns

## Notes

- Redis must be configured for high availability
- Consider Redis Cluster for scaling beyond single instance
- Rate limits must be conservative to avoid API suspension
- Some brokers count different operations differently
- Implement gradual request release to avoid bursts
- Consider time-of-day patterns in limit allocation
- Account for network latency in rate calculations

## Status Updates

- **2025-08-25**: Feature spec created and documented